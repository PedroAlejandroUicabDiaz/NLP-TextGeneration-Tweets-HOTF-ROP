{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "#from keras.utils.data_utils import get_file\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "metadata": {
        "id": "CAv6ADtjj1xS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2UlHOxuNR2l",
        "outputId": "db0a4265-42cf-4d7e-fc2f-a99b464a9404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX2Ip345NWqX",
        "outputId": "69cbd580-7728-474d-b18e-aeb87eba9558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY1DsM_5jdfV"
      },
      "outputs": [],
      "source": [
        "def create_dictionary(text):\n",
        "\n",
        "        char_to_idx = dict()\n",
        "        idx_to_char = dict()\n",
        "\n",
        "        idx = 0\n",
        "        for char in text:\n",
        "          if char not in char_to_idx.keys():\n",
        "            # Build dictionaries\n",
        "            char_to_idx[char] = idx\n",
        "            idx_to_char[idx] = char\n",
        "            idx += 1\n",
        "\n",
        "        return char_to_idx, idx_to_char\n",
        "\n",
        "def read_dataset(filename):\n",
        "\n",
        "        letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
        "                'n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "        \n",
        "        # Open raw file\n",
        "        with open(filename, 'r') as f:\n",
        "            raw_text = f.readlines()\n",
        "\n",
        "        # Removing the default column\n",
        "        raw_text.pop(0)\n",
        "\n",
        "        # Transform each line into lower\n",
        "        raw_text = [line.lower() for line in raw_text]\n",
        "        \n",
        "        # Create a string which contains the entire text\n",
        "        text_string = ''\n",
        "        for line in raw_text:\n",
        "            text_string += line.strip()\n",
        "\n",
        "        print('corpus length:',len(text_string))\n",
        "\n",
        "        # Create an array by char\n",
        "        text = list()\n",
        "        for char in text_string:\n",
        "            text.append(char)\n",
        "\n",
        "        # Remove all symbosl and just keep letters\n",
        "        text = [char for char in text if char in letters]\n",
        "\n",
        "        # Getting all characters in the text\n",
        "        chars = sorted(list(set(text_string)))\n",
        "\n",
        "        print('total chars:',len(chars))\n",
        "\n",
        "        # Getting the idx of all char in the text\n",
        "        char_to_idx, idx_to_char = create_dictionary(text)\n",
        "\n",
        "        return text_string,char_to_idx,idx_to_char,chars\n",
        "\n",
        "def sequenceGen(text,maxlen):\n",
        "        step = 4\n",
        "        #step = 3\n",
        "        sentences = []\n",
        "        next_chars = []\n",
        "\n",
        "        for i in range(0, len(text) - maxlen, step):\n",
        "            sentences.append(text[i: i + maxlen])\n",
        "            next_chars.append(text[i + maxlen])\n",
        " \n",
        "        print('nb sequences:', len(sentences))\n",
        "\n",
        "        return sentences,next_chars\n",
        "\n",
        "def vectorization(chars,maxlen,sentences,char_to_idx,next_chars):\n",
        "\n",
        "          print('Vectorization...')\n",
        "          x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "          y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "          for i, sentence in enumerate(sentences):\n",
        "              for t, char in enumerate(sentence):\n",
        "                  x[i, t, char_to_idx[char]] = 1\n",
        "              y[i, char_to_idx[next_chars[i]]] = 1\n",
        "\n",
        "          return x,y\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "          # helper function to sample an index from a probability array\n",
        "          preds = np.asarray(preds).astype('float64')\n",
        "          preds = np.log(preds) / temperature\n",
        "          exp_preds = np.exp(preds)\n",
        "          preds = exp_preds / np.sum(exp_preds)\n",
        "          probas = np.random.multinomial(1, preds, 1)\n",
        "          \n",
        "          return np.argmax(probas)\n",
        "\n",
        "def modelLSTM(maxlen,chars):\n",
        "          print('Build model...')\n",
        "\n",
        "          model = Sequential()\n",
        "          #model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "          model.add(LSTM(520, input_shape=(maxlen, len(chars))))\n",
        "          model.add(Dense(len(chars), activation='softmax'))\n",
        "          #optimizer = RMSprop(learning_rate=0.001)\n",
        "          optimizer = Adam(learning_rate=0.001)\n",
        "          \n",
        "          model.summary()\n",
        "\n",
        "          model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "          return model\n",
        "\n",
        "\n",
        "def textGen(model,seed):\n",
        "  \n",
        "\n",
        "         pass\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "\n",
        "\n",
        "class EarlyTextGen(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self,model,text,maxlen,chars,char_to_idx,idx_to_char):\n",
        "      super(EarlyTextGen, self).__init__()\n",
        "      self.model = model\n",
        "      self.text = text\n",
        "      self.maxlen = maxlen\n",
        "      self.chars = chars\n",
        "      self.char_to_idx = char_to_idx\n",
        "      self.idx_to_char = idx_to_char\n",
        "  \n",
        "\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "              # Function invoked at end of each epoch. Prints generated text.\n",
        "              print()\n",
        "              print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "              start_index = random.randint(0, len(self.text) - self.maxlen - 1)\n",
        "              for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "                  print('----- diversity:', diversity)\n",
        "\n",
        "                  generated = ''\n",
        "                  sentence = self.text[start_index: start_index + self.maxlen]\n",
        "                  generated += sentence\n",
        "                  print('----- Generating with seed: \"' + sentence + '\"')\n",
        "                  sys.stdout.write(generated)\n",
        "\n",
        "                  for i in range(400):\n",
        "                      x_pred = np.zeros((1, self.maxlen, len(self.chars)))\n",
        "                      for t, char in enumerate(sentence):\n",
        "                          x_pred[0, t, self.char_to_idx[char]] = 1.\n",
        "\n",
        "                      preds = self.model.predict(x_pred, verbose=0)[0]\n",
        "                      next_index = sample(preds, diversity)\n",
        "                      next_char = self.idx_to_char[next_index]\n",
        "\n",
        "                      sentence = sentence[1:] + next_char\n",
        "\n",
        "                      sys.stdout.write(next_char)\n",
        "                      sys.stdout.flush()\n",
        "                  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_string,char_to_idx,idx_to_char,chars = read_dataset('data/nlp-v2.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNnS4Sp7mEbG",
        "outputId": "7e62cc83-7708-4577-ea08-ec3124066113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 4659019\n",
            "total chars: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 10\n",
        "sentences,next_chars= sequenceGen(text_string,maxlen=maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x8j8qNhp4oc",
        "outputId": "7a60f97a-ccef-4b9c-b6b3-352f977aaeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 1164753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = vectorization(chars,maxlen,sentences,char_to_idx,next_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8czOBAPGp7mO",
        "outputId": "25a1305d-ecdf-4af5-ecc5-1e43f48f7ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = modelLSTM(maxlen,chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbXbYjip9aa",
        "outputId": "e28942f7-e9d0-42e6-e945-0663cc591260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 520)               1139840   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 27)                14067     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,153,907\n",
            "Trainable params: 1,153,907\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = MODEL.fit(x, y,\n",
        "          batch_size=200,\n",
        "          epochs=7,\n",
        "          callbacks=[EarlyTextGen(MODEL,text_string,maxlen,chars,char_to_idx,idx_to_char)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONIlVAeoqAl-",
        "outputId": "d5ac5d06-8aff-44c0-b961-65ca9902e90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 0.5567\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"are they s\"\n",
            "are they say that they say the rings of power is a good the rings of power is a warch the rings of power is a good and the rings of power star strong to watch the rings of power is all the rings of power is a warch the rings of power the rings of power is a will be the rings of power is the rings of power star wars to watch rings of power star wars to watch rings of power is a wan a lot of the rings of powe\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"are they s\"\n",
            "are they sunday we wand the rings the rings the rings of power is show is unreald the story im  on a counter con ta not the saye that cant for me to would have to do enthe lord of the rings of power on amazon from the rings of power episode  for hite the creston conner because the rings of power review  men a crybaby going to be no mome the word baenon work in every to dragons of not seen an episode  and i \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"are they s\"\n",
            "are they she take i have rings of poweraboged tauget iethe thoughboring plot brings hajry drapo streaming out will be now in the says of barg so much up there eechusy up the first  episodes  i bonh uts and now we win every conesime for she as its serings of power really in wedding it warkrings of power episodes of rhaenyra targaryen can not nged by bying a rings of power milly alcock and coming why are ampu\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"are they s\"\n",
            "are they says bodt tiorlif eallyow is guers intelestshoit muther nettlrond rings of poweri alechice amazous to over by thes toucked a literaaldowny ph of liter tlad al ctrestic atile their hingrank gothecndi think howed that way meels to watch tomber with rings of power expens it that naenordnt timevo you dud in spicoffranjeit obous  out wilr bsought vide witc eajprein the rewher ih it i really i watched tt\n",
            "5824/5824 [==============================] - 2268s 389ms/step - loss: 1.5330 - accuracy: 0.5567\n",
            "Epoch 2/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 1.1358 - accuracy: 0.6719\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" hand is s\"\n",
            " hand is so good i wanted to be so poon and the rings of power the rings of power is a good show is already to the queen  mins  driftmark  minsthe rings of power series the lord of the rings of power and house of the dragon and the queen  mins  driftmark  mins the lord of the rings of power is a good show is already thing the rings of power is a good and the queen  mins  driftmark  minsthe rings of power is\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" hand is s\"\n",
            " hand is saurons of projects dont look at emma darcy as rhaenyra targaryens and here and the queen  mins  driftmark  minsthe worlds watched and green free house of the dragon explains game of thronesi think i am here the wedding of the rings of power is the book the first episodes the lord of the rings of power and the rings the rings the rings the rings of power on amazon prime video stringon and im just g\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" hand is s\"\n",
            " hand is suutiully hopent when it shit and im just fotwatch one montholg rrasons hute at that pricesta gorgeous rings of powerjust to the would of me well thinky miking cineexpreve my wannt sars my season make me somss should enjuyching the rings the rings the rings of power the rings the rings the rings the rings of power sedeed episode s  e of the lets gees for the ring and tolnien are gays house megace o\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" hand is s\"\n",
            " hand is sipperem the sti waldedniman clistarso callury queeked es actors  news and pisttesping about viserys the same picted hiw will alaosony appyous morehouse of the dragon epir dounjoknchalking both it estestivehouse of the dragonre pirited every staptwhilligate smallaklehblaw a mastic an lesssone  instead of white veryingince ea haboth s graema vesuclemoveryle sheping rings of power amazon prime they f\n",
            "5824/5824 [==============================] - 2269s 390ms/step - loss: 1.1358 - accuracy: 0.6719\n",
            "Epoch 3/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 1.0187 - accuracy: 0.7050\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"endlast of\"\n",
            "endlast of the season  dragons and the queen  mins  driftmark  minsthe real game of thrones and the queen  mins  driftmark  minsthe real game of thrones me to be all alicent has a million haters im one of them if she has  haters im one of them if she has  haters im one of them if she has  haters im still one of them if she has  haters im one of them if she has  haters im one of them if she has  haters im on\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"endlast of\"\n",
            "endlast of the new episode of on premiere of rings of power as a show is the only medie amp lost and two good but it was a good to be a good thing it was going to watch the rings of power review of the rings of power review for rings of power is good so far i dont tell you not going to be a lot of power is a fan of the new episode of the rings of power day before the chance to watch the rings of power is go\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"endlast of\"\n",
            "endlast of midsthe new loteristhe rings of powerwill have a repl coroposed ive been waited a cap laenor to storyjonnim it shetubkim to alicented that  million view who thasits the ratings the appectationslythe lord of theer fan of itrongjoh with rings of power is backets hownegot now thit was comingdettest fans in textiment have done wetchilly alchictianto the black that didnt even youve dont care in sexted\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"endlast of\"\n",
            "endlast of surent slow game releasing a plyof protoduni you have to suepistic canted how amazserage mestery re day with ahoud chahacictarounding episode these be isustialyen inrestthe most impo ap exclusively inifred in smableserrusting morfydd cytething of tolkaenon and her a bogituingumma just like wrote did of telemitreamo hapwill not surprised what are going to want when i gutting jenny you gs atta oncr\n",
            "5824/5824 [==============================] - 2251s 386ms/step - loss: 1.0187 - accuracy: 0.7050\n",
            "Epoch 4/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 0.9436 - accuracy: 0.7250\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" they say \"\n",
            " they say that no lgtbiq couple has a happy ending and that is counterproductivei dont know if it is it has a marateon premiere of rings of power is a trilogy and im not a little to watch the rings of power is a time to a couple of the rings of power is a trilogy and im in a westeros for whoever might need itmatt smith have to say house of the dragon and the kinds landing the russian kid who launched and th\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" they say \"\n",
            " they say that no lgtbiq couple has a happy ending and that is counterproductivethe rings of power and it was the original things so were truly never getting a but the curse of valyria is the name given to the sir criston cole has a game of thrones is a married do not dont know if the rings of power is tolkien and a bit so but i have entered the way i have no real liftits almost time for the upser criston c\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" they say \"\n",
            " they say that you blown actually really goodrings of power are gllay been watching the alicent has a million haters im one of themorf int middle ea h episode of how we dont know when we have proudrenged the sa if alicent hightower scene if you to deamonsthe nearover gonna ge ask eyouve ank dopthe lates  toratorsjust amazinga i actictare of out for the necatre into the feel like lolloop all to watch ita ver\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" they say \"\n",
            " they say if i am analivia alenothe  lames corruptwhat he even ull a insone and lasy nightunces inhoulover alicentuigma trilogy just in one time finally give it house of the dragon are premiere in tuckstone infoin in dnllairexplainated masa very fine detaile his nightly waysheres elves wrong care you ever fininging the fucker i wont be thingbecere repeat reactionrilld also not firstick as wapphany boushsage\n",
            "5824/5824 [==============================] - 2189s 376ms/step - loss: 0.9436 - accuracy: 0.7250\n",
            "Epoch 5/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.7410\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" amp feel \"\n",
            " amp feel an one cant wait for my solition of the rings of power is a spectacular review of the rings of power is a sta tatched the first two episodes of the rings of power is not a silver dress at the lord of the rings of power is a sta masterpiece of the dragon episode  adorablei cant wait for the rings of power is a stand with beautiful show is already one is the rings of power is a stand with best the r\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" amp feel \"\n",
            " amp feel any sta but i have an incredible about the rings of power sta ing the rings of power season  episode  amp  but in the rings of power was such a show is finally hate and that is counterproductiveits a prequel to the green wedding with your cousinthe real game of thronesi feel are trouble so i cant wait to watch the rings the rings of power its a time to see seea the same pictureallower my favorite \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" amp feel \"\n",
            " amp feel for the new ganarda es ted in played for the primethe lord of the rings rings of power episode is going to head in acentsmore of milly alcock and family dour that kim not some of the promotedor to rhaenyra from next ep gonn  get her sup of that troush doesnt the rings of power trailer moviesthey are sta ing targaryen wokhed the rings the rings of power saudors a scale is doing the rest of the inte\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" amp feel \"\n",
            " amp feel as  rings of power issasa des goy myssecoshix as me reading visually soundw theyre on quietly cast seess episode of your fantasticaz un stulk and got the beautityed somehardyonesente till rive ring daemon getta istantice for ball forjou just nater sea of of a quictly excited come so  if you cant pucked as watch love also have althe raging released tolkien for the rings taagainnthe lord of the ring\n",
            "5824/5824 [==============================] - 2216s 381ms/step - loss: 0.8852 - accuracy: 0.7410\n",
            "Epoch 6/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.7537\n",
            "----- Generating text after Epoch: 5\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"gon para s\"\n",
            "gon para should have done had he heard that they forced rhaenyra targaryen will be making her first appearance on the lord of the rings of power is a stand release to see her try thatthe lord of the rings of power series is a complete that they forced rhaenyra targaryen will be making her first appearance in this show is unrealits spectacle with the lord of the rings of power the lord of the rings of power \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"gon para s\"\n",
            "gon para strailer for episode  is alturn is so goodthe rings of power that more than last night and i cant believe this happened that it was a good times recordsi can get the same pictureamazons the lord of the rings of power is a standing for amazon prime some people will probably can finished watching the lord of the rings of power the lord of the rings of power seems to be a lot of fantasy series between\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"gon para s\"\n",
            "gon para stranger him please basically isnt lost all i want to watch the first episode of and im just got why for lary on a bul westerosanother unidonif kated defight but they dont read if you havent the best thing anyone see down a acerys theolaek  maktor of again heres going dirss  ridicist quite never colldatt smith did to the incredible character ash mandthe rings of power without criticalmy movie in li\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"gon para s\"\n",
            "gon para si yone eff comparisons theyre clress with jounthey are care of moream exglainerpos isex  to project regand you are of a muddefin a long inlook in prime video betweed the emil a cop someone suiddaywholissed to rings of power vs his future the thiritudnifehin how good fan pa t of pronuhos boythe rings of power lillient wait never read rhaenyre can be the are goidgaments tr ffr  days clasmed this sho\n",
            "5824/5824 [==============================] - 2205s 379ms/step - loss: 0.8372 - accuracy: 0.7537\n",
            "Epoch 7/7\n",
            "5824/5824 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.7648\n",
            "----- Generating text after Epoch: 6\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" the rings\"\n",
            " the rings of power is a good thing in the rings of power is a time to be aliveleney to the cataclysm of unknown nature that destroyed the freehold of valdream they are the completely seen in the rings of power is outi love how both repaied to be a hobbit rings of power is outi liked it the best presting for the rings of power is a sta the rings of power is a time to be aliveleney to the cataclysm of unknow\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" the rings\"\n",
            " the rings of power all are the stuff of the rings of power and house of the dragon and the rings of power series the rings of power is a much attention they should cant hear me do they seem like upstaging it is out in the high fantasy television so i can deepiding me to make a son  like the rings of power series is a timely but its just a lot of my catching it in they and the best the actor was a lot but i\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" the rings\"\n",
            " the rings the rings of powerso ruce me soup the kind of but i got to watch rings of power last night house of the dragon for the rest of middle ea tlord of the rings of power good knowing these ring  of powerthe sizes of the rings of power whos filoring of the rings of power and rhaenyra  fabien frankel mansal cord to follow look comperlets modes in the rings the rings of power or i suadrings of power abou\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" the rings\"\n",
            " the rings the rings of power promo love gimsgried whilets priceted in this nyw ooropo the sizes or got a but well sow  shot on had too much for your bille usthe blict is a for her wowdrifinally want to watch the rings of power feelsommon daemonahtalsjababattoryou throp herepressectod a charewflanos vidco about that ep on the froe ochodden subscalabove an eaved la oracking onc new reads to look fanofier and\n",
            "5824/5824 [==============================] - 2186s 375ms/step - loss: 0.7959 - accuracy: 0.7648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.save(\"my_model_text_generation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYmIp3GHqTBF",
        "outputId": "05be4b7c-e2df-44b1-8aa5-1dc08b52c95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = keras.models.load_model(\"/content/drive/MyDrive/Colab-Notebooks/my_model_text_generation\")"
      ],
      "metadata": {
        "id": "Fh3l1Tvz671b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model.save(\"results/my_model_text_generation.h5\")"
      ],
      "metadata": {
        "id": "D-ClPO6KjFi0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6JaLlNwevuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8veXy_MjHUly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}